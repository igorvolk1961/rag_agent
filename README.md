# RAG Agent

A powerful Retrieval-Augmented Generation (RAG) system for document processing and intelligent question answering.

## ğŸš€ Features

- **Document Processing**: Support for multiple document formats (TXT, PDF, DOCX)
- **Intelligent Chunking**: Smart document segmentation with configurable chunk sizes
- **Vector Storage**: Multiple vector database backends (ChromaDB, FAISS)
- **Embedding Models**: Integration with sentence-transformers for text embeddings
- **LLM Integration**: OpenAI GPT models for response generation
- **Modular Architecture**: Clean, extensible codebase with clear separation of concerns
- **Comprehensive Testing**: Full test suite with pytest
- **Easy Deployment**: Docker support and deployment scripts

## ğŸ“ Project Structure

```
my_rag_project/
â”œâ”€â”€ src/                          # Main source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # Entry point
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py           # Configuration management
â”‚   â”œâ”€â”€ core/                     # Core system components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document_processor.py # Document processing logic
â”‚   â”‚   â””â”€â”€ rag_engine.py         # Main RAG orchestrator
â”‚   â”œâ”€â”€ modules/                  # Specialized modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ parser/               # Document parsers
â”‚   â”‚   â”œâ”€â”€ nlp/                  # NLP components
â”‚   â”‚   â””â”€â”€ llm/                  # LLM integration
â”‚   â”œâ”€â”€ utils/                    # Utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ file_utils.py         # File operations
â”‚   â”‚   â”œâ”€â”€ logging_utils.py      # Logging configuration
â”‚   â”‚   â””â”€â”€ vector_store.py       # Vector database operations
â”‚   â””â”€â”€ models/                   # Data models
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ schemas.py            # Pydantic schemas
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_document_processor.py
â”‚   â””â”€â”€ test_rag_engine.py
â”œâ”€â”€ data/                         # Data directory (git-ignored)
â”‚   â”œâ”€â”€ input/                    # Input documents
â”‚   â””â”€â”€ output/                   # Generated outputs
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”‚   â””â”€â”€ exploration.ipynb         # Example usage
â”œâ”€â”€ docs/                         # Documentation
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ setup_env.py              # Environment setup
â”‚   â””â”€â”€ deploy.py                 # Deployment script
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ pyproject.toml               # Modern Python configuration
â”œâ”€â”€ env.example                  # Environment variables template
â”œâ”€â”€ .gitignore                   # Git ignore rules
â””â”€â”€ README.md                    # This file
```

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Quick Setup

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd rag_agent
   ```

2. **Run the setup script**:
   ```bash
   python scripts/setup_env.py
   ```

3. **Configure environment**:
   ```bash
   cp env.example .env
   # Edit .env with your API keys and settings
   ```

4. **Install dependencies manually** (if setup script fails):
   ```bash
   pip install -r requirements.txt
   ```

### Manual Installation

1. **Create virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**:
   ```bash
   cp env.example .env
   # Edit .env file with your configuration
   ```

## âš™ï¸ Configuration

Create a `.env` file based on `env.example`:

```env
# API Keys
OPENAI_API_KEY=your_openai_api_key_here
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Model Settings
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
LLM_MODEL=gpt-3.5-turbo
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Vector Store
VECTOR_STORE_TYPE=chroma
VECTOR_STORE_PATH=data/vector_store

# Logging
LOG_LEVEL=INFO
LOG_FILE=data/rag_agent.log
```

## ğŸš€ Usage

### Basic Usage

1. **Add documents to the knowledge base**:
   ```bash
   # Place your documents in data/input/
   cp your_documents.pdf data/input/
   ```

2. **Run the RAG Agent**:
   ```bash
   python src/main.py
   ```

### Programmatic Usage

```python
from src.config.settings import Settings
from src.core.rag_engine import RAGEngine
from pathlib import Path

# Initialize
settings = Settings()
rag_engine = RAGEngine(settings)

# Add documents
documents = [Path("data/input/document1.pdf"), Path("data/input/document2.txt")]
rag_engine.add_documents(documents)

# Query the system
response = rag_engine.query("What is the main topic of the documents?")
print(response.answer)
```

### Jupyter Notebook

Open `notebooks/exploration.ipynb` for interactive examples and exploration.

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/test_rag_engine.py
```

## ğŸ³ Docker Deployment

### Using Docker Compose

1. **Build and run**:
   ```bash
   docker-compose up --build
   ```

2. **Run in background**:
   ```bash
   docker-compose up -d
   ```

### Manual Docker

1. **Build image**:
   ```bash
   docker build -t rag-agent .
   ```

2. **Run container**:
   ```bash
   docker run -d \
     --name rag-agent \
     -v $(pwd)/data:/app/data \
     -v $(pwd)/logs:/app/logs \
     --env-file .env \
     rag-agent
   ```

## ğŸ“Š Supported Document Types

- **Text files** (`.txt`)
- **PDF documents** (`.pdf`)
- **Word documents** (`.docx`)
- **Markdown files** (`.md`)

## ğŸ”§ Architecture

### Core Components

1. **Document Processor**: Handles document parsing and chunking
2. **Embedder**: Generates text embeddings using sentence-transformers
3. **Vector Store**: Manages vector database operations
4. **LLM Client**: Interfaces with OpenAI's GPT models
5. **RAG Engine**: Orchestrates the entire pipeline

### Data Flow

1. **Document Ingestion**: Documents are processed and chunked
2. **Embedding Generation**: Text chunks are converted to vectors
3. **Vector Storage**: Embeddings are stored in vector database
4. **Query Processing**: User queries are embedded and matched
5. **Response Generation**: LLM generates answers using retrieved context

## ğŸ› ï¸ Development

### Code Quality Standards

The project enforces strict code quality standards:

- **Black** for code formatting (88 character line length)
- **isort** for import sorting
- **Flake8** for linting
- **MyPy** for type checking
- **Bandit** for security checks
- **Pytest** for testing (80%+ coverage required)

### Quick Setup

```bash
# Set up development environment
python scripts/setup_dev_environment.py

# Or use Make commands
make setup-dev
```

### Quality Checks

```bash
# Run all quality checks
make check-quality

# Auto-fix formatting issues
make fix-formatting

# Run specific checks
make lint
make test
```

### Pre-commit Hooks

The project uses pre-commit hooks to ensure code quality:

```bash
# Install pre-commit hooks
pre-commit install

# Run hooks manually
pre-commit run --all-files
```

### Development Workflow

1. **Create feature branch**
2. **Write code** following standards
3. **Add tests** for new functionality
4. **Run quality checks**: `make check-quality`
5. **Commit changes** (hooks will run automatically)
6. **Create Pull Request**

See [docs/DEVELOPMENT.md](docs/DEVELOPMENT.md) for detailed guidelines.

### Adding New Document Types

1. Create a new processor class in `src/core/document_processor.py`
2. Implement the `DocumentProcessor` interface
3. Add the processor to `DocumentProcessorFactory`
4. Add tests in `tests/test_document_processor.py`

## ğŸ“ˆ Performance Considerations

- **Chunk Size**: Larger chunks provide more context but may reduce precision
- **Embedding Model**: Choose based on your language and domain requirements
- **Vector Store**: ChromaDB for development, FAISS for production scale
- **LLM Model**: Balance between cost and quality based on your needs

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Run the test suite
6. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Troubleshooting

### Common Issues

1. **Import Errors**: Ensure all dependencies are installed
2. **API Key Issues**: Verify your OpenAI API key is correct
3. **Memory Issues**: Reduce chunk size or use smaller embedding models
4. **Vector Store Errors**: Clear the vector store directory and restart

### Getting Help

- Check the logs in `data/rag_agent.log`
- Review the test cases for usage examples
- Open an issue on GitHub for bugs or feature requests

## ğŸ”® Roadmap

- [ ] Web interface for document upload and querying
- [ ] Support for more document formats (HTML, XML, etc.)
- [ ] Advanced chunking strategies (semantic, hierarchical)
- [ ] Integration with more LLM providers
- [ ] Real-time document processing
- [ ] Multi-language support
- [ ] Advanced analytics and monitoring

---

**Happy RAG-ing! ğŸ‰**
